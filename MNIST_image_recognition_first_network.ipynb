{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_image_recognition_first_network.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilge-idTech/Artificial-Intelligence-and-Machine-Learning-with-NVIDIA/blob/main/MNIST_image_recognition_first_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idWn_agaVyVq"
      },
      "source": [
        "#Preparing the Data\n",
        "\n",
        "Keras has code that will load a basic version of some data into lists in Python, but they aren't yet formatted in a way that your neural network will be able to use.\n",
        "\n",
        "Reshaping and processing data into a format that the neural network can consume is a key step in any machine learning problem.\n",
        "\n",
        "In this lesson, you will learn how to prepare the MNIST dataset so that it can be put into a neural network. \n",
        "\n",
        "\n",
        "##Set up and Importing\n",
        "\n",
        "\n",
        "The first stage of this process is to import all the libraries you will need; to set up variables to keep track of the important information about your data. Then you will import the data and save it so that it is ready to be cleaned up and processed.\n",
        "\n",
        "1. Run this cell to import all the necesary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVy2ab5YV5QE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# helper functions\n",
        "def show_min_max(array, i):\n",
        "  random_image = array[i]\n",
        "  print(random_image.min(), random_image.max())\n",
        "\n",
        "def plot_image(array, i, labels):\n",
        "  plt.imshow(np.squeeze(array[i]))\n",
        "  plt.title(\" Digit \" + str(labels[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plHm5C7EWAH5"
      },
      "source": [
        "## The image data\n",
        "\n",
        "There are some things you should know about the MNIST dataset. \n",
        "\n",
        "**Image Size:** Each image is 28 x 28 pixels\n",
        "\n",
        "**Amount of images:** there are 60,000 training and 10,000 testing images\n",
        "\n",
        "**Amount of output classes:** Since image is a digit from 0-9 there are ten possible output classes.\n",
        "\n",
        "**Colors: **These images have one color channel which means that each pixel is currently stored as a value between 0 and 255\n",
        "\n",
        "1. Use this information to set these variables to the correct amount."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhIz2ZSzWlVw"
      },
      "source": [
        "# Set image size\n",
        "img_rows = \n",
        "img_cols = \n",
        "# Set the number of output classes\n",
        "num_classes = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozsnTDz6XgUv"
      },
      "source": [
        "Now, you can load the data into your program. This line will load data to train the model, and data to test it, as well as the labels to test the data against.Since you are going to be processing this data and manipulating it, it makes sense to have a backup of the untouched data.\n",
        "\n",
        "2. Run this cell to load the data and a backup copy.\n",
        "3. Check to be sure that you have the correct data by pringing out the shape of the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rojv4pAXh8e"
      },
      "source": [
        "# Load in the data\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "(train_images_backup, train_labels_backup), (test_images_backup, test_labels_backup) = mnist.load_data() \n",
        "# Print the shape of the data\n",
        "print(train_images.shape) \n",
        "print(test_images.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYHl47wtXjXl"
      },
      "source": [
        "###Data Formatting\n",
        "\n",
        "\n",
        "Sometimes, data can be formatted in many different ways, and a Machine Learning expert will need to handle this in their code. Since the MNIST data is already so well prepared for machine learning applications there isn't a lot of reshaping or preparation that needs to go into it.\n",
        "\n",
        "However, in other situations, you might come across data that needs more hefty reshaping and re-organizing. This is an important skill to develop, and as you expand your machine learning abilities you will learn more about how to deal with different types of data. \n",
        "\n",
        "For now, you will just reshape the data so that it is an appropriate size for your network. The code belowtakes data that was originally a list of pixels, and reshapes it into a 28x28 grid, which matches how our neural network will process the data.\n",
        "\n",
        "\n",
        "1. Add another line to reshape the test images the same way as the train images.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AITJjdZxXkoF"
      },
      "source": [
        "# Reshape the training data.\n",
        "train_images = train_images.reshape(train_images.shape[0],  img_rows, img_cols, 1) \n",
        "# Repeat the code above with the test images.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPAGQP28YoAd"
      },
      "source": [
        "2. Create an input_shape variable to keep track of the shape of your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYP_VtXYYrmU"
      },
      "source": [
        "# Set input shape for later use.\n",
        "input_shape = (img_rows, img_cols, 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAtgfDDbYuDs"
      },
      "source": [
        "###Data Cleaning\n",
        "\n",
        "\n",
        "Now that the data is in the right format, we can do some simple data cleaning.  The color in pixels is stored as an integer value between 0 and 255.  While your network can learn from this information, it will be easier if we replace these values with a decimal between 0 and 1.  This keeps the numbers the network is dealing with small.\n",
        "\n",
        "We do this by changing the data to a float32, a kind of decimal number, and then doing some division to get the 0-1 values you want.\n",
        "\n",
        "1. Run the cell below to see the 100th image in the dataset, and what the min and max value in that image is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TdJSAe-Y9eb"
      },
      "source": [
        "#  Display an image, and the min and max values in it\n",
        " plot_image(train_images, 100, train_labels)\n",
        " show_min_max(train_images, 100) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IW24-hkZGND"
      },
      "source": [
        "In order for the network to better understand the data, you are going to convert it to a float between 0 and 1. \n",
        "\n",
        "2. Run the cell below to convert the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrKQOjpkWI8D"
      },
      "source": [
        "# Convert data into float32\n",
        "train_images = train_images.astype('float32') \n",
        "# Divide the images by 255\n",
        "train_images /= 255 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibu2KQ_NWdgq"
      },
      "source": [
        "3. Repeat the same code as above with the test images dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY4PO6FvWbY6"
      },
      "source": [
        "# Convert test images into float 32\n",
        "\n",
        "# Divide test images by 255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NAhtdHFWYn6"
      },
      "source": [
        "4. Check to make sure that the min and max of the images are 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6uExikNZUxY"
      },
      "source": [
        "# Check that the images have been updated.\n",
        "plot_image(train_images, 100, train_labels)\n",
        "show_min_max(train_images, 100)\n",
        "\n",
        "plot_image(test_images, 100, test_labels) \n",
        "show_min_max(test_images, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgERjPebaHOn"
      },
      "source": [
        "### One-Hot Encoding\n",
        "\n",
        "\n",
        "MNIST is a set of hand-drawn images of the numbers 0-9. The label for each image is then simply the number 0-9.\n",
        "\n",
        "However, there is a problem with this.  Due to how neural networks function, they intuitively believe that the image labeled \"1\" is more similar to the image labeled \"0\" or \"2\" than the image labeled \"7\".  However, that's not the case.  If you write a 0, 1, 2, and 7 on a sheet of paper, the 1 and 7 are more similar in structure, with a long straight line compared with the curves in 0 or 2.\n",
        "\n",
        "One-Hot Encoding is a technique that helps solve this problem by replacing the label on each image with a representation that the network won't think is ordered, so it will view each number independently.\n",
        "\n",
        "1. Repeat the code below to employ one-hot coding on the test dataset as well as the train dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlcZuNkLaSaQ"
      },
      "source": [
        "# Do one-hot encoding on train dataset\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes) \n",
        "# Repeat the code above with test_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmUPC7k7acrm"
      },
      "source": [
        "#Building a Network\n",
        "\n",
        "**Neural networks** learn to accomplish their tasks by reading training data and adjusting their neuron weights to improve their chance of choosing the correct answer.\n",
        "\n",
        "The first kind of network you will create is a densely connected network. In this network, layers of neurons are connected to each other. The output from one layer becomes the input for the next one. These layers manipulate and reshape the data so that the computer can make a guess as to what the output should be.\n",
        "\n",
        "You are going to use a framework called TensorFlow to build, compile and run your first neural network that will be able to detect handwritten digits. \n",
        "\n",
        "1. Run this code to import the needed libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sOjWdRlajQ1"
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Flatten "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNp8llMnbVa0"
      },
      "source": [
        "###Epochs\n",
        "\n",
        "\n",
        "Training is done in a sequence of rounds called epochs. Each epoch is one pass over the dataset.  Meaning, in each epoch, every image in the dataset is passed through your model once.  Generally, the more epochs you run, the better your results, but the longer it will take to train.  Finding the sweet spot between good results and reasonable runtime is a big challenge in training a model.\n",
        "\n",
        "To start, run 10 epochs.\n",
        "\n",
        "1. Set the epochs variable to ten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeheioq4bbnV"
      },
      "source": [
        "# Set the epochs variable\n",
        "epochs =  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiwbKExlbeiV"
      },
      "source": [
        "###Model Type\n",
        "\n",
        "\n",
        "You'll be making a sequential model. Sequential models are split into layers. A layer is one set of neurons that processes the inputs from the previous layer, then passes it along to the next layer.  The first layer reads in the original data, and the final layer produces the network's prediction.\n",
        "\n",
        "Determining how many and what kinds of layers to use, and configuring each individual layer is the meat of building a neural network. You'll do this in the next steps, but first, define your model:\n",
        "\n",
        "1. Run the cell to create a sequential model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0uugXzEbhGz"
      },
      "source": [
        "# Create your model\n",
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8ssGtNpbwQN"
      },
      "source": [
        "###Add The First Layer\n",
        "\n",
        "\n",
        "The first layer to add to this network is a flatten layer. This will take your prepared image data and flatten it into a long series of numbers representing pixels (remember when we prepared the data for this?). This allows the network to take in the data from the image and begin to perform calculations with it. This layer is also known as the input layer, as it takes input.\n",
        "\n",
        "This layer needs to know what the input shape is. Luckily, while preparing the data, we saved the input shape to a variable, so we can use that. \n",
        "\n",
        "1. Inside the parentheses add the input shape by setting input shape equal to your saved input_shape from before. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OO2o0dpb1N6"
      },
      "source": [
        "# Add the first layer, and set the input shape.\n",
        "model.add(Flatten(input_shape= ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEzKE7lEcMqe"
      },
      "source": [
        "##Adding the Calculation Layers\n",
        "\n",
        "\n",
        "Next, we need to add a layer to perform predictions on the data. There are a lot of different configurations for this middle part, and a lot of machine learning research is about how to best set these layers up.\n",
        "\n",
        "For right now, you are going to add just two, with 16 neurons. You will also need to decide on an activation algorithm. \n",
        "\n",
        "1. In the cell below, finish the network by adding a second calculation layer before the first. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9if5J-QcLgS"
      },
      "source": [
        "# Add a calculation layer.\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "# Use the same code as above to create a second calculation layer here:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9Cj_zFdAbM"
      },
      "source": [
        "### Output Layers\n",
        "\n",
        "\n",
        "The final stage of the network is the output layer. It needs to shrink the previous layer down to just the number of possible classes.  Then, each output of this final layer represents the network's guess on how likely the input is to be from that class.\n",
        "\n",
        "Note that this means that the network produces multiple results for each image, one for each class.  The final decision of the model is the class with the highest weight, determined during training and testing.\n",
        "\n",
        "Since this data has digits from 0-9, there are ten possible answers. \n",
        "\n",
        "1. Set the units for the output layer to the number of output classes.\n",
        "2. Run the cell to see output of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQDI9wqMdDhw"
      },
      "source": [
        "# Add the output layer\n",
        "model.add(Dense(units= , activation='softmax'))\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW_SV4y4cqe5"
      },
      "source": [
        "As you can see from the output, we have a sequential model, with four layers that reshape the data. There are already 13,002 parameters to train. This means that the network is going to adjust 13,002 numbers each time it runs an epoch. Hopefully, this will be enough to correctly identify the number in the image. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpdU-uHsdlj3"
      },
      "source": [
        "##Compiling and Training the Network\n",
        "\n",
        "\n",
        "Now, it is time to compile the network. Tensorflow has a command that will do a lot of the work for you, but you still need to set up a few arguments so that this network is compiled in a way that is useful to you.\n",
        "\n",
        "You are going to add this line to compile your network and then read below to learn more about what each argument represents.  \n",
        "\n",
        "1. Run the cell below to compile the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbT7ItSvcEBL"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',  optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZGrwdS9fRUU"
      },
      "source": [
        "###Training\n",
        "\n",
        "\n",
        "Now that you have a compiled model, you can fit that model to the actual data that you prepared. The fit stage will use the training data to train the model to recognize numbers.\n",
        "\n",
        "The train_images data set will be the input, the train_labels will keep track of if the network guess is correct or not, and the epochs will be equal to the variable you set up earlier. \n",
        "\n",
        "1. Run the cell below to start training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4nQR2Vid4yW"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=epochs, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ew5XrTfxJz"
      },
      "source": [
        "For each epoch, you can see the loss and the accuracy of the network on the training data. As you can see, the accuracy goes up with each epoch, and the loss goes down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWQUfnrLfb80"
      },
      "source": [
        "###Analyzing the Output\n",
        "\n",
        "\n",
        "Knowing how well the model did on the training data isn't very useful.  It doesn't mean much if you can get an A on a test where you're given the answers.\n",
        "\n",
        "The real test of a model is how well it does on data it hasn't seen before and doesn't know the labels for.  That's exactly what the model.evaluate function is for.\n",
        "\n",
        "This function takes the trained model and the test data and produces a set of scores, or metrics, that show how well the model did on this test data.\n",
        "\n",
        "While model.evaluate takes the test labels as input, they're never shown to the neural network, only used to compare the network's answer to the real answer.\n",
        "\n",
        "After evaluation, the final point of this function is to return the model object for use later as needed. \n",
        "\n",
        "1. Run the cell below to see the accuracy of the network you created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_8-5wd0eWAm"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdiS-d6SfnKb"
      },
      "source": [
        "The test accuracy tells you how accurate the network was with the test data. \n",
        "\n",
        "For this particular run, this model was 95% accurate on the test data. That's pretty good! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NhZ6aOWf0nL"
      },
      "source": [
        "#Recap\n",
        "\n",
        "Neural networks add layers of neurons to perform calculations on the data. They use these layers to make predictions about the data that they are being used on. First, they are trained using training data, and then tested using test data. There are a lot of parameters that can be adjusted to make the network better. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR6KRntJg7z6"
      },
      "source": [
        "Now that you understand the basics of creating a model, it's time to play with it and see what you can change.\n",
        "\n",
        "\n",
        "\n",
        "* Add another calculation layer. Write down how the accuracy and loss. How is it different than with just one calculation layer? \n",
        "\n",
        "\n",
        "- Run the model with only one epoch. How does the accuracy change? \n",
        "\n",
        "\n",
        "- Try to crash the runtime by making a network too big or too slow.\n",
        "\n",
        "\n",
        "- What happens if you change the input shape? What about epochs? \n",
        "\n",
        "\n",
        "- Can you get the test accuracy to be higher? What do you need to change? \n",
        "\n",
        "\n",
        "- Make the output shape for a layer super large or super small. How does that affect the test accuracy? What about the amount of time the model takes to run? \n",
        "\n"
      ]
    }
  ]
}